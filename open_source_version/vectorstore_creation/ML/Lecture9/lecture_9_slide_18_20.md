# Slide 18 of Lecture 9 contains information about Neural Networks.

# Here is what the image 1 in slide 18 of lecture 9 contains:

The image consists of two main sections, an upper and a lower diagram, illustrating a Deep LSTM example. Both sections represent a network of interconnected nodes with descriptive labels and lines indicating connections.

**Upper Diagram:**
- Nodes are colored gray, with labels such as "sum", "sigmoid", "bias", "tanh", and "multiply".
- Starts with two "input" nodes connected to three layers, each having multiple sets of nodes in the sequence "sum", "sigmoid", "bias" or "sum", "tanh", "bias". 
- These layers connect to nodes labeled "multiply", which further connect to additional nodes incorporating a mix of processing elements and terminating into various "multiply" nodes.
- Arrows between nodes vary in shades, with the outermost arrows connected to "multiply" nodes colored green, orange, blue, and purple.
- Contains the text: "Deep LSTM Example (previous iteration)" to the right.

**Lower Diagram:**
- Nodes are colored blue and connected in a pattern similar to the upper diagram.
- Two yellow "input" nodes connect to forms of layers with nodes labeled "sum", "sigmoid", "bias" and "sum", "tanh", "bias".
- Black lines denote connections between nodes, leading to and from each process node to "multiply" nodes, following a pattern similar to the upper network.
- Blue lines transition into orange at the rightmost "sum", "sigmoid", and "bias" nodes.
- Contains the text: "Deep LSTM Example."

**Additional Elements:**
- There's a simplified illustration on the right side depicting yellow and blue circles inter-connected by lines, with an orange circle at the end.


https://www.asimovinstitute.org/wp-content/uploads/2016/12/neuralnetworkgraphs.png
