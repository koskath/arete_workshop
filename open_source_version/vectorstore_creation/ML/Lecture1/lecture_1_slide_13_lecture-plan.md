# Slide 13 of Lecture 1 contains information about the Lecture Plan.

Here is what the image 1 in slide 13 of lecture 1 contains:

The image is a table with five columns and sixteen rows, detailing a course schedule. The columns are labeled "Lecture," "Teacher," "Topic(s)," and "Readings."

1. **Header Row**:
   - Titles from left to right: "Lecture," "Teacher," "Topic(s)," "Readings."
   
2. **Row 1**:
   - Lecture: "Lecture-01 Week #06"
   - Teacher: "SM"
   - Topic(s): "Course practicalities & Introduction to course"
   - Readings: "[HML] Ch 1"

3. **Row 2**:
   - Lecture: "Lecture-02 Week #06"
   - Teacher: "SM"
   - Topic(s): "Introduction to machine learning; Data pre-processing and exploratory data analysis"
   - Readings: "[HML] Ch 2"

4. **Row 3**:
   - Lecture: "Lecture-03 Week #08"
   - Teacher: "SM"
   - Topic(s): "Principles of unsupervised machine learning; K-Means, DBSCAN, Hierarchical clustering"
   - Readings: "[HML] Ch 9"

5. **Row 4**:
   - Lecture: "Lecture-04 Week #08"
   - Teacher: "SM"
   - Topic(s): "Principles of supervised machine learning; KNN, Linear and Logistic regression"
   - Readings: "[HML] Ch 3 and 4"

6. **Row 5**:
   - Lecture: "Lecture-05 Week #09"
   - Teacher: "SM"
   - Topic(s): "Dimensionality Reduction: Principal Component Analysis, Decision Trees, Ensembles: Random Forests"
   - Readings: "[HML] Ch 8"

7. **Row 6**:
   - Lecture: "Lecture-06 Week #09"
   - Teacher: "SM"
   - Topic(s): "Boosting: Gradient Boosting, Support Vector Machines (SVM); Performance Metrices of ML"
   - Readings: "SVM: [HML] ch, 5; Decision trees: [HML] ch. 6; Ensembles and random forest: [HML] ch. 7"

8. **Row 7**:
   - Lecture: "Lecture-07 Week #10"
   - Teacher: "SM"
   - Topic(s): "Outlier Detection: Isolation Forest, Recommender Systems, Class imbalance: SMOTE and ADASYN"
   - Readings: "SMOTE: [J01] section 4.2 and ADASYN: [J02]"

9. **Row 8**:
   - Lecture: "Lecture-08 Week #10"
   - Teacher: "SM"
   - Topic(s): "Gradient Descent problem, Batch and mini-batch gradient descent, Regularization (L0, L1, early stopping and dropout regularization), Batch normalization."
   - Readings: "[HML] Ch 4"

10. **Row 9**:
    - Lecture: "Lecture-09 Week #11"
    - Teacher: "SM"
    - Topic(s): "Neural Networks: General Introduction, Threshold Logic Units (TLU), Multi-Layer Perceptron with Many Layers, Feedforward network"
    - Readings: "[HML]: Ch 10"

11. **Row 10**:
    - Lecture: "Lecture-10 Week #11"
    - Teacher: "SM"
    - Topic(s): "Introduction Tensor flow, RNN, Distributed DL"
    - Readings: "[https://www.tensorflow.org/tutorials/] & [HML]: Ch 10"

12. **Row 11**  
   - Lecture: "Lecture-11 Week #12"  
   - Teacher: "SM"  
   - Topic(s): "Long short-term memory (LSTM), Gated Recurrent Unit."  
   - Readings: "[HML]: Ch 15"

13. **Row 12**  
   - Lecture: "Lecture-12 Week #12"  
   - Teacher: "SM"  
   - Topic(s): "Autoencoder, Hyper Parameter Optimizations"  
   - Readings: ""

14. **Row 13**  
   - Lecture: "Lecture-13 Week #13"  
   - Teacher: "SM"  
   - Topic(s): "CNN, Adversarial attacks"  
   - Readings: "[HML]: Ch 14"

15. **Row 14**  
   - Lecture: "Lecture-14 Week #13"  
   - Teacher: "SM"  
   - Topic(s): "Philosophy of AI, Ethics of ML and DL, AI alignment"  
   - Readings: ""

16. **Row 15**  
   - Lecture: "Lecture-15 Week #15"  
   - Teacher: "SM"  
   - Topic(s): "Federated learning, Explainable artificial intelligence, Reinforcement learning"  
   - Readings: ""

17. **Row 16**  
   - Lecture: "Lecture-16 Week #15"  
   - Teacher: "SM"  
   - Topic(s): "Recap and conclusion; Project Consultations; Groups meetings"  
   - Readings: ""
