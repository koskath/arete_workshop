# Slide 8 of Lecture 12 contains information about the Stacked Autoencoder.

Stacked or deep autoencoders extend the basic architecture with multiple hidden layers, allowing the model to capture more complex codings. A typical MNIST autoencoder might start with 784 input units, feed them into a 100-neuron hidden layer, compress them further into a 30-neuron coding layer, expand back through another 100-neuron hidden layer, and finally reconstruct the 784-dimensional output. T
