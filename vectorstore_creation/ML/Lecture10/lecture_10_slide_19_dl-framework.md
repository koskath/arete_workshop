# Slide 19 of Lecture 10 contains information about the DL Framework.

DL frameworks hide most of the mathematics and let practitioners focus on neural-net design, making deep-learning experimentation faster and more accessible.

Representative frameworks include Google TensorFlow/Keras, PyTorch (https://pytorch.org/), Caffe (https://caffe.berkeleyvision.org/), and Microsoft Cognitive Toolkit (https://cntk.ai), each offering optimized libraries for building and training models.

These tools enable ever-larger and deeper models such as LeNet (1998), AlexNet (2012, which laid the groundwork for VGG and ResNet), the 2015 Residual Neural Network (ResNet-50), and the Transformer architecture introduced in 2017.
