# Slide 27 of Lecture 14 contains information about the RL Example: AlphaZero.

Introduced in 2017, AlphaZero is a unified system that taught itself chess, shogi, and Go from scratch by playing millions of self-play games. To master each game, an untrained neural network begins with random moves, then iteratively updates its parameters based on the outcomes of wins, losses, and draws to favor advantageous strategies. Training duration scales with game complexity, taking roughly nine hours for chess, twelve hours for shogi, and thirteen days for Go.
