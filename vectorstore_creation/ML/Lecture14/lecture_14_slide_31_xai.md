# Slide 31 of Lecture 14 contains information about the XAI.

Explainable AI focuses on answering stakeholder questions about how models make decisions so that requirements are met during development, debugging, and testing. Rising ethical concerns have made transparency essential, and XAI encompasses processes that foster human understanding and trust, improve auditability, and mitigate compliance, legal, security, and reputational risks. Meeting expectations around fairness, explainability, and accountability is central to productive AI use.
