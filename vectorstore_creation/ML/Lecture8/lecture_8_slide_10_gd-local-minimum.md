# Slide 10 of Lecture 8 contains information about the GD: Local Minimum.



Gradient Descent (GD) is an iterative optimization algorithm used to find the local minimum of a function, often referred to as '$f$'. The process begins with an initial guess, denoted as $w^0$. The core of the algorithm involves generating a new guess by moving in the negative gradient direction of the function at the current point, as shown by the formula: $w^1 = w^0 - \alpha \nabla f(w^0)$. Here, $\alpha$ is the learning rate (or "step size"), which determines the magnitude of the step taken. If the step size $\alpha$ is chosen to be small enough, this move will decrease the value of '$f$'. Conversely, if the value of '$f$' increases, the step size $\alpha$ should be decreased. This step is then repeated successively to refine the guess using the general update rule: $w^{t+1} = w^t - \alpha \nabla f(w^t)$ for $t = 0, 1, 2, 3, \dots$ . The algorithm is designed to stop if it is no longer making progress or when the magnitude of the gradient, $\|\nabla f(w^t)\|$, is less than or equal to a small scalar $\epsilon$, indicating that an approximate local minimum has been reached. Under weak conditions—specifically, if '$f$' is bounded, its gradient $\nabla f$ doesn't change arbitrarily fast, and $\alpha$ is small and constant—the algorithm is expected to converge to a weight vector '$w$' where the gradient is zero, i.e., $\nabla f(w) = 0$.